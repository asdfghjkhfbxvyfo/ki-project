{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 36\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"The Module has been build for creating a dataset with images + ground truth\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m   on a Raspberry Pi 4 with a standard USB camera. An image with a resolution \u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m   of 640px x 480px is recorded and you can control image recording plus ground \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m   Pizza Hawaii<3\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m   \"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Imports\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# =============================================================================\n",
    "# Created By:     Kai Metzger\n",
    "# Created School: Franz-Oberthuer-Schule Wuerzburg\n",
    "# Created Email:  metzgerkai@franz-oberthuer-schule.de\n",
    "# Created Date:   Fri February 23 07:31:00 UTC 2024\n",
    "# Version:        1.0\n",
    "# =============================================================================\n",
    "\"\"\"The Module has been build for creating a dataset with images + ground truth\n",
    "   on a Raspberry Pi 4 with a standard USB camera. An image with a resolution \n",
    "   of 640px x 480px is recorded and you can control image recording plus ground \n",
    "   truth creation via pressing the following keys on the keyboard:\n",
    "   - ESC:       Quit\n",
    "   - SPACE:     Take picture (*without pressing BACKSPACE before) and save into \n",
    "                folders data/ground_truth. Increment counter by + 1.\n",
    "   - BACKSPACE  Search folders and start image/gt file counters with highest \n",
    "                count (i. e. already taken 100 images --> images names 0 - 99, \n",
    "                next image with <100.png> and gt with 100.txt).\n",
    "   - 0          Use label 0 for grount truth and write it to .txt file.\n",
    "   - ...        \"\n",
    "   - 3          \"\n",
    "\n",
    "   You can change the script to fit your needs (i. e. create more classes,\n",
    "   choose different keys, etc.)\n",
    "\n",
    "   Camera window has to be active for user input (add new data, abort/exit, \n",
    "   etc.)\n",
    "   \"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# Imports\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# =============================================================================\n",
    "# Imports and other stuff you could remove\n",
    "# =============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# Config\n",
    "# =============================================================================\n",
    "# Create folders in dataset path for data, gt (ground truth) and \n",
    "# chpt (checkpoint) folder\n",
    "dataset_path = \"/home/pi/ki-project/home/pi/images/hergenroether\"\n",
    "\n",
    "# =============================================================================\n",
    "# Camera setup\n",
    "# =============================================================================\n",
    "# Settings for image recording\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(3,640) # set Width\n",
    "cam.set(4,480) # set Height       \n",
    "cv2.namedWindow(\"camera\")\n",
    "\n",
    "# =============================================================================\n",
    "# Variables\n",
    "# =============================================================================\n",
    "img_counter = 4\n",
    "\n",
    "# =============================================================================\n",
    "# Main loop to record new images, abort with CTRL+C\n",
    "# =============================================================================\n",
    "try:\n",
    "    while True:\n",
    "        # Image related stuff\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print(\"failed to grab frame\")\n",
    "            break\n",
    "        cv2.imshow(\"camera\", frame)\n",
    "\n",
    "        # Press some keys to record images, and then press another key, \n",
    "        # i. e. 0 to write the first index into the text file.\n",
    "        k = cv2.waitKey(1)\n",
    "        if k == 27:\n",
    "            # ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "        if k == 8:\n",
    "            # BACKSPACE pressed\n",
    "            # Search folder for already recorded images&ground truth data\n",
    "            list_data = glob.glob(dataset_path +\"/data/*\")\n",
    "            list_gt = glob.glob(dataset_path + \"/gt/*\")\n",
    "            #print(list_data)\n",
    "            img_counter = len(list_data)\n",
    "            gt_counter = len(list_gt)\n",
    "            #print(count_gt\n",
    "            \n",
    "            # image count = GT-Anzahl?\n",
    "            if (img_counter != gt_counter):\n",
    "                print(\"Images and annotated data are not equal!\")\n",
    "                \n",
    "            print(\"Continue with :\" + str(img_counter))\n",
    "        elif k == 32:\n",
    "            # SPACE pressed\n",
    "            img_name = dataset_path + \"/data/{}.png\".format(img_counter)\n",
    "            gt_name = dataset_path + \"/gt/{}.txt\".format(img_counter)\n",
    "\n",
    "            # Save image ave in folder /dataset/<number+1>.png\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            #print(frame.shape)\n",
    "            print(\"{} written!\".format(img_name))\n",
    "            \n",
    "            class_label = None\n",
    "            print(\"Enter class label for current image, press ...\\n \\\n",
    "                  0 = cross \\n \\\n",
    "                  1 = circle \\n \\\n",
    "                  2 = square \\n \\\n",
    "                  3 = triangle\")\n",
    "            # Enter class label (0:circle or 1:rectangle or ...)\n",
    "            # on keyboard, caution: Num-Pad does not work here!\n",
    "            c = cv2.waitKey(-1)\n",
    "            if c == 48: # ASCII 48 = key 0 on keyboard\n",
    "                class_label = 0\n",
    "            if c == 49: # ASCII 49 = key 1 on keyboard\n",
    "                class_label = 1\n",
    "            if c == 50: # ASCII 50 = key 2 on keyboard\n",
    "                class_label = 2      \n",
    "            if c == 51: # ASCII 51 = key 3 on keyboard\n",
    "                class_label = 3\n",
    "            print(\"Class = \", class_label)\n",
    "            \n",
    "            # GT in folder and /dataset/ground_truth/<number+1>.txt\n",
    "            with open(gt_name, \"w\") as text_file:\n",
    "                    text_file.write(str(class_label))\n",
    "            print(\"{} written!\".format(gt_name))\n",
    "\n",
    "            # Increment by 1 for image and ground truth\n",
    "            img_counter += 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Program aborted!\")\n",
    "finally:\n",
    "    # =========================================================================\n",
    "    # Clean exit\n",
    "    # =========================================================================\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eom:46349): EOM-WARNING **: 15:36:08.514: Error loading Peas typelib: Typelib file for namespace 'Peas', version '1.0' not found\n",
      "\n",
      "\n",
      "(eom:46349): EOM-WARNING **: 15:36:08.514: Error loading PeasGtk typelib: Typelib file for namespace 'PeasGtk', version '1.0' not found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# creating a object\n",
    "im = Image.open(\"/home/pi/ki-project/ki-project/raw_data/Sechseck/KIBild59.jpg\")\n",
    "\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size: 53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Imports\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "from tensorflow.keras import layers, models, utils, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To get reproducable results with the same training setting random seed\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# =============================================================================\n",
    "# Imports and other stuff you could remove\n",
    "# =============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =============================================================================\n",
    "# Declare variables\n",
    "# =============================================================================\n",
    "img_size_x = 28\n",
    "img_size_y = 28\n",
    "img_dim = img_size_x * img_size_y\n",
    "img_dir = '/home/pi/ki-project/ki-project/raw_data/Sechseck'\n",
    "gt_dir = '/home/pi/ki-project/ki-project/raw_data/Sechseck'\n",
    "checkpoint_filepath = '/home/pi/ki-project/home/pre_made_datasets/dataset2/Checkpoint'\n",
    "\n",
    "# destination filepathes for image preperation\n",
    "cnt_path = '/home/pi/ki-project/ki-project/c_nr'\n",
    "shape_path = '/home/pi/ki-project/ki-project/shape'\n",
    "gt = '/gt'\n",
    "im = '/data'\n",
    "chpt = '/chpt'\n",
    "\n",
    "# =============================================================================\n",
    "# Get number of data (image/label) \n",
    "# =============================================================================\n",
    "anz_data = len(os.listdir(img_dir))\n",
    "anz_data = int(anz_data) - 1\n",
    "dataset = np.zeros((anz_data, img_size_x, img_size_y), dtype=float)\n",
    "ground_truth = np.zeros((anz_data), dtype=int)\n",
    "print(\"dataset size:\", anz_data)\n",
    "\n",
    "# =============================================================================\n",
    "# Main loop to record new images, abort with CTRL+C\n",
    "# =============================================================================\n",
    "try:\n",
    "    while True:\n",
    "        # Image related stuff\n",
    "        ret, frame = im.read()\n",
    "        if not ret:\n",
    "            print(\"failed to grab frame\")\n",
    "            break\n",
    "        im.imshow(\"bild\", frame)\n",
    "\n",
    "        # Press some keys to record images, and then press another key, \n",
    "        # i. e. 0 to write the first index into the text file.\n",
    "        k = im.waitKey(1)\n",
    "        if k == 27:\n",
    "            # ESC pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            break\n",
    "\n",
    "        if k == 8:\n",
    "            # BACKSPACE pressed\n",
    "            # Search folder for already recorded images&ground truth data\n",
    "            list_data = glob.glob(dest_path +\"/data/*\")\n",
    "            list_gt = glob.glob(dest_path + \"/gt/*\")\n",
    "            #print(list_data)\n",
    "            img_counter = len(list_data)\n",
    "            gt_counter = len(list_gt)\n",
    "            #print(count_gt)\n",
    "            \n",
    "            # image count = GT-Anzahl?\n",
    "            if (img_counter != gt_counter):\n",
    "                print(\"Images and annotated data are not equal!\")\n",
    "\n",
    "        print(\"Continue with :\" + str(img_counter))\n",
    "    elif k == 32:\n",
    "            # SPACE pressed\n",
    "            img_name = dataset_path + \"/data/{}.png\".format(img_counter)\n",
    "            gt_name = dataset_path + \"/gt/{}.txt\".format(img_counter)\n",
    "\n",
    "            # Save image ave in folder /dataset/<number+1>.png\n",
    "            cv2.imwrite(img_name, frame)\n",
    "            #print(frame.shape)\n",
    "            print(\"{} written!\".format(img_name))\n",
    "            \n",
    "            class_label_no = None\n",
    "            class_label_shape = None\n",
    "            print(\"Enter class label for current image, press ...\\n \\\n",
    "                  a = circle \\n \\\n",
    "                  d = square \\n \\\n",
    "                  f = hexagon \\n \\\n",
    "                  s = octagon \\n \\\n",
    "                  and number of balls\")\n",
    "        \n",
    "            # Enter class label (0:circle or 1:rectangle or ...)\n",
    "            # on keyboard, caution: Num-Pad does not work here!\n",
    "            c = im.waitKey(-1)\n",
    "            if c == 48: # ASCII 48 = key 0 on keyboard\n",
    "                class_label_no = 0\n",
    "            if c == 49: # ASCII 49 = key 1 on keyboard\n",
    "                class_label_no = 1\n",
    "            if c == 50: # ASCII 50 = key 2 on keyboard\n",
    "                class_label_no = 2      \n",
    "            if c == 51: # ASCII 51 = key 3 on keyboard\n",
    "                class_label_no = 3\n",
    "            if c == 52: # ASCII 52 = key 4 on keyboard\n",
    "                class_label_no = 4\n",
    "            if c == 53: # ASCII 53 = key 5 on keyboard\n",
    "                class_label_no = 5\n",
    "            if c == 54: # ASCII 54 = key 6 on keyboard\n",
    "                class_label_no = 6\n",
    "            if c == 55: # ASCII 55 = key 7 on keyboard\n",
    "                class_label_no = 7\n",
    "            if c == 56: # ASCII 56 = key 8 on keyboard\n",
    "                class_label_no = 8\n",
    "            if c == 57: # ASCII 57 = key 9 on keyboard\n",
    "                class_label_no = 9\n",
    "\n",
    "            if c == 97: # a = circle\n",
    "                class_label_shape = 0\n",
    "            if c == 100: # d = square\n",
    "                class_label_shape = 2\n",
    "            if c == 102: # f = hexagon\n",
    "                class_label_shape = 3\n",
    "            if c == 115: # s = octagon\n",
    "                class_label_shape = 1\n",
    "\n",
    "            # GT in folder and /dataset/ground_truth/<number+1>.txt\n",
    "            with open(gt_name, \"w\") as text_file:\n",
    "                    text_file.write(str(class_label_no))\n",
    "            print(\"{} written!\".format(gt_name))\n",
    "        \n",
    "            # GT in folder and /dataset/ground_truth/<number+1>.txt\n",
    "            with open(gt_name, \"w\") as text_file:\n",
    "                    text_file.write(str(class_label_shape))\n",
    "            print(\"{} written!\".format(gt_name))\n",
    "\n",
    "            # Increment by 1 for image and ground truth\n",
    "            img_counter += 1\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Program aborted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# GPT Train\n",
    "# ===========================================\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_form_cnn():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(len(class_names_form), activation='softmax')  # Anzahl der Formen\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Modell erstellen\n",
    "model_form = create_form_cnn()\n",
    "\n",
    "# Training starten\n",
    "model_form.fit(x_train_form, y_train_form, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# GPT Kugelanzahl erkennung\n",
    "# ================================\n",
    "\n",
    "def create_ball_count_cnn():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='linear')  # Regression for Kugelanzahl\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])  # MSE for Regression\n",
    "    return model\n",
    "\n",
    "# Modell erstellen\n",
    "model_balls = create_ball_count_cnn()\n",
    "\n",
    "# Training starten\n",
    "model_balls.fit(x_train_balls, y_train_balls, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# GPT Optimieren\n",
    "# ========================================\n",
    "\n",
    "def convert_to_tflite(model, filename):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "convert_to_tflite(model_form, \"form_model.tflite\")\n",
    "convert_to_tflite(model_balls, \"balls_model.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# GPT Echtzeit-Erkennung\n",
    "# ==================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.lite as tflite\n",
    "\n",
    "# Modelle laden\n",
    "interpreter_form = tflite.Interpreter(model_path=\"form_model.tflite\")\n",
    "interpreter_form.allocate_tensors()\n",
    "\n",
    "interpreter_balls = tflite.Interpreter(model_path=\"balls_model.tflite\")\n",
    "interpreter_balls.allocate_tensors()\n",
    "\n",
    "# Kamera starten\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_resized = cv2.resize(frame, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n",
    "\n",
    "    # Form erkennen\n",
    "    interpreter_form.set_tensor(interpreter_form.get_input_details()[0]['index'], input_data)\n",
    "    interpreter_form.invoke()\n",
    "    form_output = interpreter_form.get_tensor(interpreter_form.get_output_details()[0]['index'])\n",
    "    form_class = np.argmax(form_output)\n",
    "\n",
    "    # Kugelanzahl erkennen\n",
    "    interpreter_balls.set_tensor(interpreter_balls.get_input_details()[0]['index'], input_data)\n",
    "    interpreter_balls.invoke()\n",
    "    ball_count = interpreter_balls.get_tensor(interpreter_balls.get_output_details()[0]['index'])\n",
    "\n",
    "    print(f\"Erkannte Form: {list(class_names_form.keys())[form_class]}\")\n",
    "    print(f\"Kugelanzahl: {int(ball_count[0])}\")\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================\n",
    "# GPT ergebnisse an SPS senden\n",
    "# =================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.lite as tflite\n",
    "from pymodbus.client import ModbusTcpClient\n",
    "\n",
    "# SPS Konfiguration\n",
    "SPS_IP = \"192.168.1.100\"\n",
    "SPS_PORT = 502\n",
    "client = ModbusTcpClient(SPS_IP, port=SPS_PORT)\n",
    "\n",
    "# Modelle laden\n",
    "interpreter_form = tflite.Interpreter(model_path=\"form_model.tflite\")\n",
    "interpreter_form.allocate_tensors()\n",
    "\n",
    "interpreter_balls = tflite.Interpreter(model_path=\"balls_model.tflite\")\n",
    "interpreter_balls.allocate_tensors()\n",
    "\n",
    "# Kamera starten\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Form Mapping\n",
    "form_mapping = {0: \"octagon\", 1: \"circle\", 2: \"square\"}\n",
    "\n",
    "def send_to_sps(form, ball_count):\n",
    "    \"\"\"Sendet die erkannten Werte an die SPS.\"\"\"\n",
    "    if not client.connect():\n",
    "        print(\"❌ Verbindung zur SPS fehlgeschlagen!\")\n",
    "        return\n",
    "\n",
    "    form_value = list(form_mapping.keys())[list(form_mapping.values()).index(form)]\n",
    "\n",
    "    client.write_register(0, form_value)   # Register 0 = Form\n",
    "    client.write_register(1, ball_count)   # Register 1 = Kugelanzahl\n",
    "    print(f\"✅ Gesendet: Form = {form} ({form_value}), Kugeln = {ball_count}\")\n",
    "\n",
    "    client.close()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_resized = cv2.resize(frame, (128, 128)) / 255.0\n",
    "    input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32)\n",
    "\n",
    "    # Form erkennen\n",
    "    interpreter_form.set_tensor(interpreter_form.get_input_details()[0]['index'], input_data)\n",
    "    interpreter_form.invoke()\n",
    "    form_output = interpreter_form.get_tensor(interpreter_form.get_output_details()[0]['index'])\n",
    "    form_class = np.argmax(form_output)\n",
    "    form_name = form_mapping.get(form_class, \"unknown\")\n",
    "\n",
    "    # Kugelanzahl erkennen\n",
    "    interpreter_balls.set_tensor(interpreter_balls.get_input_details()[0]['index'], input_data)\n",
    "    interpreter_balls.invoke()\n",
    "    ball_count = int(interpreter_balls.get_tensor(interpreter_balls.get_output_details()[0]['index'])[0])\n",
    "\n",
    "    print(f\"📸 Erkannte Form: {form_name}, Kugeln: {ball_count}\")\n",
    "\n",
    "    # Ergebnisse an SPS senden\n",
    "    send_to_sps(form_name, ball_count)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
