{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models, utils, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Declare variables\n",
    "dataset_path = \"/home/pi/ki-project/home/pi/images/hergenroether\"\n",
    "img_size_x = 32\n",
    "img_size_y = 24\n",
    "img_dim = img_size_x * img_size_y\n",
    "img_dir = '/home/pi/ki-project/ki-project/raw_data/Sechseck'\n",
    "gt_dir = '/home/pi/ki-project/ki-project/raw_data/Sechseck'\n",
    "checkpoint_filepath = '/home/pi/ki-project/home/pre_made_datasets/dataset2/Checkpoint'\n",
    "\n",
    "# destination filepathes for image preperation\n",
    "dest_path = '/home/pi/ki-project/ki-project/c_nr'\n",
    "dest_gt = '/home/pi/ki-project/ki-project/c_nr/gt'\n",
    "dest_im = '/home/pi/ki-project/ki-project/c_nr/data'\n",
    "dest_chpt = '/home/pi/ki-project/ki-project/c_nr/chpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of data (image/label) \n",
    "anz_data = len(os.listdir(img_dir))\n",
    "anz_data = int(anz_data) - 1\n",
    "dataset = np.zeros((anz_data, img_size_x, img_size_y), dtype=float)\n",
    "ground_truth = np.zeros((anz_data), dtype=int)\n",
    "print(\"dataset size:\", anz_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change image size and convert to grayscale images\n",
    "def pic_prep (image, x, y):\n",
    "  image = cv2.resize(image, (y,x))                # change image size\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "  image = image / 255                             # image normalization\n",
    "  return image\n",
    "\n",
    "# Shuffle images\n",
    "def unison_shuffle(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for training\n",
    "\n",
    "# Set verbose flag to 0 to omit loss/accuracy output per epoch\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath + \"chpt.keras\",\n",
    "    save_weights_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=True,\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "for i in range(0, anz_data, 1):\n",
    "    img_name = img_dir + '/' + str(i) + '.png'      # create file names\n",
    "    image = cv2.imread(img_name)                    # read image\n",
    "    image = pic_prep(image, img_size_x, img_size_y) # prepare image\n",
    "    dataset[i,:,:] = image                          # 2d-image to 3d-array\n",
    "    \n",
    "    txt_name = gt_dir + '/' + str(i) + '.txt'       # create gt file names\n",
    "    ground_truth[i] = np.genfromtxt(txt_name, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset: train set (80%) and test set (20%)\n",
    "dataset = dataset.reshape(anz_data, img_dim) # convert into 2d array (all pixel in one row)\n",
    "ground_truth = ground_truth.reshape(anz_data, 1)\n",
    "\n",
    "dataset, ground_truth = unison_shuffle(dataset, ground_truth)\n",
    "\n",
    "trainset = np.random.choice(dataset.shape[0],\n",
    "                            int(dataset.shape[0]*0.80), \n",
    "                            replace=False)\n",
    "train_data = dataset[trainset,:]\n",
    "train_gt = ground_truth[trainset]\n",
    "train_gt = utils.to_categorical(train_gt, 4)\n",
    "\n",
    "testset = np.delete(np.arange(0, len(ground_truth) ), \n",
    "                    trainset) \n",
    "test_data = dataset[testset,:]\n",
    "test_gt = ground_truth[testset]\n",
    "test_gt = utils.to_categorical(test_gt, 4)\n",
    "\n",
    "#print(ground_truth)\n",
    "#print(dataset)\n",
    "#print(trainset)\n",
    "#print(train_data)\n",
    "#print(train_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create neural network with 4 layers and (64, 32, 16, 4) neurons per layer.\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64,input_dim=img_dim,activation='relu'))\n",
    "model.add(layers.Dense(32,activation='relu'))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dense(4,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neuronal network e.g. for 300 epochs.\n",
    "history = model.fit(train_data, \n",
    "                    train_gt, \n",
    "                    batch_size=4, \n",
    "                    epochs=300, \n",
    "                    verbose=0, \n",
    "                    shuffle=True, \n",
    "                    validation_data=(test_data, test_gt), \n",
    "                    callbacks=[model_checkpoint_callback])\n",
    "\n",
    "# Plot train and val accuracy.\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot train and val loss.\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained dataset weights to e.g. test on new (unseen) data.\n",
    "model.load_weights(checkpoint_filepath + \"chpt.keras\")\n",
    "\n",
    "# Test dataset on xxx.\n",
    "score = model.evaluate(test_data, test_gt, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Testing on a single image.\n",
    "data_pred = np.zeros((1, img_size_x, img_size_y), dtype=float)\n",
    "img_pred = cv2.imread(home_dir + \"/ml_project/datasets/symbols/dataset1/data/14.png\")\n",
    "img_pred = pic_prep(img_pred, img_size_x, img_size_y)\n",
    "data_pred[0,:,:] = img_pred\n",
    "data_pred = data_pred.reshape(1,img_dim)\n",
    "result = model.predict(data_pred)\n",
    "result = np.round(result, decimals=2)\n",
    "\n",
    "print(\"Probability for classes: (cross, circle, triangle, square) in percent\", \n",
    "      result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output class: \n",
    "# translate class label (0,1,2,3) to class (cross, circle, triangle, square).\n",
    "\n",
    "max_res = 0\n",
    "res_index = 4\n",
    "for i in range(0, 4, 1):\n",
    "    if result[0,i] > max_res:\n",
    "        max_res = result[0,i]\n",
    "        res_index = i\n",
    "\n",
    "if res_index == 0:\n",
    "    print('Cross detected!')\n",
    "elif res_index == 1:\n",
    "    print('Circle detected!')\n",
    "elif res_index == 2:\n",
    "    print('Triangle detected!')\n",
    "elif res_index == 3:\n",
    "    print('Square detected!')\n",
    "elif res_index == 4:\n",
    "    print('Error!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
